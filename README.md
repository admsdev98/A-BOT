# ü§ñ A-BOT - Asistente Virtual de Adam

## Descripci√≥n

A-BOT es mi asistente virtual creado por y para vosotros, que os contestar√° cualquier pregunta relacionada sobre m√≠ y el mundo laboral.

**üí° Este proyecto ha sido desarrollado con la ayuda de [Cursor](https://cursor.sh).**

## ‚ú® Caracter√≠sticas

- **Chat interactivo**: Interfaz web amigable para conversar con el bot
- **Informaci√≥n completa**: Respuestas sobre experiencia laboral, habilidades, proyectos y educaci√≥n
- **IA avanzada**: Utiliza el modelo `phi4-mini` a trav√©s de Ollama para respuestas inteligentes, pensando en aquellas personas que tengan PC poco potentes
- **Arquitectura moderna**: Backend en FastAPI y frontend en Streamlit
- **Dockerizado**: F√°cil despliegue y ejecuci√≥n con Docker

## üèóÔ∏è Arquitectura

El proyecto est√° estructurado en dos componentes principales:

### Backend (FastAPI)
- **API REST**: Endpoint `/chat` para procesar consultas
- **Servicio de IA**: Integraci√≥n con LangChain y Ollama
- **Gesti√≥n de contexto**: Informaci√≥n personal y profesional estructurada

### Frontend (Streamlit)
- **Interfaz web**: Chat interactivo y responsive
- **Gesti√≥n de sesi√≥n**: Mantiene el historial de conversaci√≥n
- **UX optimizada**: Dise√±o moderno y f√°cil de usar

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Backend
- **FastAPI**: Framework web moderno y r√°pido
- **Uvicorn**: Servidor ASGI para FastAPI
- **LangChain**: Framework para aplicaciones de IA
- **LangChain-Ollama**: Integraci√≥n con Ollama
- **Ollama**: Servidor local de modelos LLM
- **Pydantic**: Validaci√≥n de datos

### Frontend
- **Streamlit**: Framework para aplicaciones web de datos
- **HTTPX**: Cliente HTTP as√≠ncrono

### DevOps
- **Docker**: Containerizaci√≥n de la aplicaci√≥n
- **Docker Compose**: Orquestaci√≥n de servicios

## ‚ö†Ô∏è Importante

> **‚ö†Ô∏è Primera ejecuci√≥n lenta**: La primera vez que ejecutes el proyecto, tardar√° varios minutos en descargar el modelo de IA `phi4-mini` (~3GB). Las siguientes ejecuciones ser√°n mucho m√°s r√°pidas.

## üì¶ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- **Docker** y **Docker Compose** instalados
- **4GB+ de RAM** para ejecutar el modelo LLM
- **Conexi√≥n a internet** para la primera descarga del modelo

### Instalaci√≥n Local (sin Docker)

1. **Clonar el repositorio:**
   ```bash
   git clone <url-del-repositorio>
   cd A-BOT
   ```

2. **Crear entorno virtual:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # o
   venv\Scripts\activate     # Windows
   ```

3. **Instalar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Instalar Ollama:**
   ```bash
   curl -fsSL https://ollama.ai/install.sh | sh
   ```

5. **Descargar el modelo:**
   ```bash
   ollama pull phi4-mini
   ```

6. **Ejecutar el backend:**
   ```bash
   cd src/backend
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

7. **Ejecutar el frontend (nueva terminal):**
   ```bash
   cd src/frontend
   streamlit run app.py
   ```

### Instalaci√≥n con Docker (Recomendado)

1. **Clonar el repositorio:**
   ```bash
   git clone <url-del-repositorio>
   cd A-BOT
   ```

2. **Ejecutar con Docker Compose:**
   ```bash
   cd docker
   docker-compose up --build
   ```

3. **Acceder a la aplicaci√≥n:**
   - Frontend: http://localhost:8501
   - Backend API: http://localhost:8000

## üõ†Ô∏è Uso

1. **Abrir el navegador** y navegar a http://localhost:8501
2. **Ver el mensaje de bienvenida** de A-BOT
3. **Escribir preguntas** sobre Adam en el chat
4. **Recibir respuestas** basadas en su informaci√≥n profesional

### Ejemplos de preguntas

- "¬øCu√°l es la experiencia laboral de Adam?"
- "¬øQu√© tecnolog√≠as domina?"
- "¬øD√≥nde ha trabajado en 2022?"
- "¬øSabe programar con APIs?"
- "¬øQu√© metodolog√≠as utiliza?"